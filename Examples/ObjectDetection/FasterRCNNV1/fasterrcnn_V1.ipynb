{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting FasterRCNN from Pytorch to ONNX format. \n",
    "<br>\n",
    "FasterRCNN has based on different types. In this case we are exporting fasterRCNN model with compination of ResNet50 backbone and the FPN a neural network architecture designed to handle objects at different scale, which create a multi-scale feature pyramid from a single-scale input image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "\n",
    "\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating a dummy input and adjusting the size according to the model specifications\n",
    "<br>\n",
    "FasterRCNN batched in (B, C, H, W) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 3, 800, 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types senarios with dummy input in this case. According to pytorch uses `x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting FasterRCNN to ONNX needs different procedure. This is happening because of object detection tasks. The input in object detection has usually a batch of images and each tensor in the x list coresponds to one image image in the batch. In this case using images of different sizes, the model can handle more variations of input sizes. \n",
    "\n",
    "\n",
    "Summary:\n",
    "<br>\n",
    "The dummy input in the model represents two different-sized images to demonstrate the model's ability to handle variable input dimensions. It is for simplicity reasons to use a standard input tensor rather than a variety of input tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    \"fasterrcnn_resnet50_fpn.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"]\n",
    ") \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model,\n",
    "                  input,\n",
    "                  \"fasterrcnn_resnet50_fpn.onnx\",\n",
    "                  input_names=[\"input\"],\n",
    "                  output_names=[\"output\"],\n",
    "                  dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic axes specifies that the input can vary in dimencions, more or less than 800x800px while output has in this case fixed output dims. Sometimes output dimensions can also vary depending on the architecture of the given model. In this case it is assigned using more batched data than in given input with variable width and height input featured map `dynamic_axes={\"input\": {0: \"batch_size\", 2: \"height\", 3: \"width\"}, \"output\": {0: \"batch_size\"}}`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input names: input\n",
      "Output names: output\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort \n",
    "\n",
    "fasterrcnn_resnet50_fpn_onnx = ort.InferenceSession(\"fasterrcnn_resnet50_fpn.onnx\")\n",
    "\n",
    "print(\"Input names:\", fasterrcnn_resnet50_fpn_onnx.get_inputs()[0].name)\n",
    "print(\"Output names:\", fasterrcnn_resnet50_fpn_onnx.get_outputs()[0].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification of the Exported Model Using Netron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"input_fasterrcnn.png\" alt=\"Input of fasterrcnn in Netron\" width=\"1000\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"output_fasterrcnn.png\" alt=\"Ouput of fasterrcnn in Netron\" width=\"1000\" height=\"500\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
